---
title: "Análise de Dados"
author: "Rui Mendes"
date: "28/02/2021"
output:
  ioslides_presentation:
    widescreen: true
    smaller: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, comment = NA)
library(tidyverse)
library(factoextra)
library(broom)
```

## Horário:
- 19 de Março das 9 às 13
- 20 de Março das 10 às 12

## Aulas e avaliação

- Metodologia TBL
- Trabalho em grupo
- Avaliação de pares
  - *intra*-grupo
  - *extra*-grupo
- Projeto
  - Escolher um dataset
  - Analisar o dataset
  - Produzir uma apresentação de análise do dataset
  - Colocar num projeto Github

## Sugestões de datasets

- [Eurostat](https://cran.r-project.org/web/packages/eurostat/index.html)
- [Covid-19](https://github.com/CSSEGISandData)
- [FluMOMO](https://www.euromomo.eu/how-it-works/flumomo/)
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)

## Ir buscar o R
1. Ir a https://www.r-project.org/
1. Escolher o mirror
2. Escolher o sistema operativo
3. Ir buscar o base
4. Instalar
5. Ir buscar o RStudio

## Como instalar pacotes no R
- Configurar o mirror (Packages -> Set mirror)
- Usar o comando *install.packages* ou
- Usar a opção do R (Packages -> Install packages)

## Cheat sheets
Eis o URL: https://rstudio.com/resources/cheatsheets/

- Data Import Cheatsheet
- Data Transformation Cheatsheet
- Data Visualization Cheatsheet
- Apply Functions Cheatsheet
- R Markdown Cheatsheet
- RStudio IDE Cheatsheet

## Pacotes a instalar
- tidyverse
- broom
- factoextra

## Funções interessantes para analisar dados
- head
- summary
- count
- select
- Sobre tibbles
  - filter
  - group_by
  - mutate
  - summarise





## Tidyverse
Temos que importar o módulo *Tidyverse*

```{r, echo = TRUE}
library(tidyverse)
```

- Instala bastantes pacotes
- Possui muitas funções interessantes para a análise de dados

## Dataset que vamos utilizar neste exemplo
```{r}
mpg
```


## Que atributos tem o dataset?

```{r}
mpg %>% names
```

## Selecionar atributos

```{r}
mpg %>% select(year, cyl, cty, hwy, drv, fl)
```

## Selecionar linhas e atributos

```{r}
mpg %>% select(year, cyl, cty, hwy, drv, fl) %>% filter(cyl == 6)
```

## Agrupamentos
Autonomia por tipo de combustível e cilindrada na auto-estrada

```{r}
mpg %>% group_by(fl, cyl) %>%
  summarize(media = mean(hwy), contagem = n(), .groups = "keep")
```

## COVID em Portugal

```
url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
read_csv(url) %>% filter(`Country/Region` == "Portugal") %>%
  pivot_longer(matches("\\d+/\\d+/\\d+"), values_to = "confirmados") %>%
  mutate(across(name, ~parse_datetime(.x, "%m/%d/%y"))) %>%
  ggplot(aes(x = name, y = confirmados)) + geom_line() + labs(x = "Data")
```

## COVID em Portugal

```{r, echo = FALSE, message = FALSE}
url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
read_csv(url) %>% filter(`Country/Region` == "Portugal") %>%
  pivot_longer(matches("\\d+/\\d+/\\d+"), values_to = "Confirmados") %>%
  mutate(across(name, ~parse_datetime(.x, "%m/%d/%y"))) %>%
  ggplot(aes(x = name, y = Confirmados)) + geom_line() + labs(x = "Data")
```

## COVID em Portugal

```{r, echo = FALSE, message = FALSE}
url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
read_csv(url) %>% filter(`Country/Region` == "Portugal") %>%
  pivot_longer(matches("\\d+/\\d+/\\d+"), values_to = "Mortos") %>%
  mutate(across(name, ~parse_datetime(.x, "%m/%d/%y"))) %>%
  ggplot(aes(x = name, y = Mortos)) + geom_line() + labs(x = "Data")
```

## COVID

```{r, echo = FALSE, message = FALSE}
url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
read_csv(url) %>% group_by(`Country/Region`) %>% summarize(across(matches("\\d+/\\d+/\\d+"), sum)) %>%
  filter(`Country/Region` == "France" | `Country/Region` == "Spain" | `Country/Region` == "Portugal" | `Country/Region` == "Italy") %>%
  pivot_longer(matches("\\d+/\\d+/\\d+"), values_to = "Mortos") %>%
  mutate(across(name, ~parse_datetime(.x, "%m/%d/%y"))) %>%
  ggplot(aes(x = name, y = Mortos, color = `Country/Region`)) + geom_line() + labs(x = "Data")
```

## COVID

```{r, echo = FALSE, message = FALSE}
url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
read_csv(url) %>% group_by(`Country/Region`) %>% summarize(across(matches("\\d+/\\d+/\\d+"), sum)) %>%
  filter(`Country/Region` == "France" | `Country/Region` == "Spain" | `Country/Region` == "Portugal" | `Country/Region` == "Italy") %>%
  pivot_longer(matches("\\d+/\\d+/\\d+"), values_to = "Mortos") %>%
  mutate(across(name, ~parse_datetime(.x, "%m/%d/%y"))) %>%
  ggplot(aes(x = name, y = Mortos, color = `Country/Region`, shape = `Country/Region`)) + geom_point() + labs(x = "Data") + facet_wrap(vars(`Country/Region`))
```


##  Wisconsin Diagnostic Breast Cancer (WDBC)
- 32 campos
- id
- diagnosis
- 10 medidas com 3 valores:
  - mean
  - standard error
  - worst
  
## WDBC medidas  
- radius (mean of distances from center to points on the perimeter)
- texture (standard deviation of gray-scale values)
- perimeter
- area
- smoothness (local variation in radius lengths)
- compactness (perimeter^2 / area - 1.0)
- concavity (severity of concave portions of the contour)
- concave points (number of concave portions of the contour)
- symmetry 
- fractal dimension ("coastline approximation" - 1)

## WDBC
```{r, message = FALSE}
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
flds = strsplit("radius texture perimeter area smoothness compactness
  concavity conv_pts symmetry fract_dim", "\\s+") %>% unlist
wdbc = read_csv(url) %>% set_names(c("id", "diagnosis",
  paste0(flds, "_mean"), paste0(flds, "_se"), paste0(flds, "_worst")))
wdbc %>% head
```

## WDBC PCA
```{r}
wdbc_pca = wdbc %>% nest(data=everything()) %>% 
  mutate(pca = map(data, ~ prcomp(.x %>% select(-id, -diagnosis), 
                                  center = TRUE, scale = TRUE)),
         pca_aug = map2(pca, data, ~augment(.x, data = .y)))
wdbc_pca
```

## WDBC PCA
```{r}
var_exp = wdbc_pca %>% unnest(pca_aug) %>% summarize(across(matches("PC\\d+"), var)) %>%
  gather(key = pc, value = variance) %>% 
  mutate(var_exp = variance/sum(variance),
         cum_var_exp = cumsum(var_exp),
         pc = str_replace(pc, ".fitted", ""))
var_exp
```

## PCA
```{r, echo = FALSE, message = FALSE}
wdbc %>% select(radius_mean:fract_dim_worst) %>% prcomp(center = TRUE, scale = TRUE) %>%
  fviz_pca_ind(geom.ind = "point", pointshape = 21,
               pointsize = 2,
               fill.ind = as.character(wdbc$diagnosis),
               col.ind = "black",
               palette = "jco",
               addEllipses = TRUE,
               label = "var",
               col.var = "black",
               repel = TRUE,
               legend.title = "Diagnosis")
```

## PCA
```{r, echo = FALSE, message = FALSE}
var_exp %>% 
  rename(
    `Variancia Explicada` = var_exp,
    `Variancia Cumulativa` = cum_var_exp
  ) %>% mutate(pc = gsub("PC(\\d)$", "PC0\\1", pc, fixed = FALSE)) %>%
  gather(key = key, value = value, `Variancia Explicada`:`Variancia Cumulativa`) %>% 
  ggplot(aes(pc, value, group = key)) + 
  geom_point() + 
  geom_line() + 
  facet_wrap(~key, scales = "free_y") +
  theme_bw() +
  lims(y = c(0, 1)) +
  labs(y = "Variance",
       title = "Variancia explicada por cada componente principal")
```

## Wine Quality
```{r, message = FALSE}
wine_url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
wine = read_delim(wine_url, delim=";")
wine %>% summary
```

## Wine Quality
```{r, message = FALSE}
wine %>% pivot_longer(cols = everything()) %>%
  group_by(name) %>% summarise_all(lst(min, mean, median, max))
```



## Bibliografia
- [R for Data Science](https://r4ds.had.co.nz/index.html)
