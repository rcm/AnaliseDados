{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNXMVjQ0hf25Y3zK6+MA3i5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcm/AnaliseDados/blob/main/PP_T_aula01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Mining\n",
        "\n",
        "## CRISP-DM\n",
        "\n",
        "![CRISP-DM](https://www.datascience-pm.com/wp-content/uploads/2021/02/CRISP-DM.png)\n",
        "\n",
        "1. Business understanding\n",
        "2. Data understanding\n",
        "3. Data preparation\n",
        "4. Modeling\n",
        "5. Evaluation\n",
        "6. Deployment\n",
        "\n",
        "## Business understanding\n",
        "- Business objectives\n",
        "- Assessment\n",
        "- Data mining goals\n",
        "- Project plan\n",
        "\n",
        "## Data understanding\n",
        "- Colect\n",
        "- Describe\n",
        "- Visualize\n",
        "- Verify quality\n",
        "\n",
        "## Data preparation\n",
        "- Select\n",
        "- Clean\n",
        "- Integrate\n",
        "- Format\n",
        "- Standardize/Discretize/Transform\n",
        "- Create new fieds\n",
        "\n",
        "## Modeling\n",
        "- Select techniques\n",
        "- Test design\n",
        "- Build model\n",
        "- Assess model\n",
        "\n",
        "## Evaluation\n",
        "- Evaluate results\n",
        "- Review process\n",
        "- Decide next step\n",
        "\n",
        "## Data mining\n",
        "- Learn from data\n",
        "- Find common patterns\n",
        "- Predict future results\n",
        "\n",
        "### Characteristics\n",
        "- Find patterns in data\n",
        "- Gather insight\n",
        "- Use existing data in order to make intelligent decisions\n",
        "- We want to find patterns in data in order to gather insight or help us take decisions\n",
        "- Structural descriptions are quite useful\n",
        "\n",
        "\n",
        "### Common problems\n",
        "- Data quality may be poor\n",
        "- Data may be missing or noisy\n",
        "- Patterns found may not be exact, not useful or simply not interesting\n",
        "\n",
        "### Common data mining tasks\n",
        "- Predictive\n",
        "  - **Classification** Predict the class\n",
        "  - **Regression** Predict a number\n",
        "  - **Time Series Analysis** Predict next value in the series\n",
        "- Descriptive\n",
        "  - **Clustering** Grouping by similarities\n",
        "  - **Summarization** Summarize and generalize data\n",
        "  - **Association Rules** Discover connection between items\n",
        "  - **Sequence Discovery** Find patterns in sequential data\n",
        "\n",
        "## Data Cleaning\n",
        "1. Import data\n",
        "2. Merge datasets\n",
        "3. Handle missing data\n",
        "4. Standardization\n",
        "5. Normalization\n",
        "6. Remove duplicates\n",
        "\n",
        "## Data Transformation\n",
        "- **Transforming** Applying a function to an attribute\n",
        "- **Summarizing** Grouping\n",
        "- **Discretization**\n",
        "  - Transform numeric values into categorical ones\n",
        "  - Binarizing\n",
        "  - Binning\n",
        "- **Handle missing values**\n",
        "  - Remove records\n",
        "  - Imputation\n",
        "    - Replace by a value\n",
        "    - Use median/mean\n",
        "    - Predict using kNN\n",
        "- **Standardization** Substitute values by the *Z score*\n",
        "- **Normalization** Rescale values to the **[0; 1]** interval\n",
        "\n",
        "## Data\n",
        "A table contains:\n",
        "- **Atributes** or columns of the dataset\n",
        "- **Records** or lines of the dataset\n",
        "- Each attribute represents a variable (e.g., salary, weight)\n",
        "- Each record represents an example\n",
        "\n",
        "\n",
        "| Name | Weight | Height | Sport |\n",
        "|:----:|:------:|:------:|:-----:|\n",
        "| John | 80 | 180|Tennis|\n",
        "|Mary|160|50|Rugby|\n",
        "|Chris|170|68|Judo|"
      ],
      "metadata": {
        "id": "RAZ66YnVvOWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python refresh course\n",
        "- lambda functions\n",
        "- enumerate\n",
        "- zip\n",
        "- list and set comprehension\n",
        " "
      ],
      "metadata": {
        "id": "JDXKytKNoANK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = lambda x: x ** 2"
      ],
      "metadata": {
        "id": "RS9Q1Aain87v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy\n",
        "- [Documentação](https://numpy.org/doc/stable/user/index.html#user)\n",
        "- [Tutorial 1](https://numpy.org/doc/stable/user/quickstart.html)\n",
        "- [Tutorial 2](https://cs231n.github.io/python-numpy-tutorial/)"
      ],
      "metadata": {
        "id": "fxtOdZcYRiJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([1,2,3])\n",
        "print(f\"{a.size} {a.ndim} {a.shape}\")\n",
        "print(a[np.newaxis, :], a[:, np.newaxis], sep = '\\n\\n')"
      ],
      "metadata": {
        "id": "SVXwjdXMXuey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.arange(1,10).reshape(3,3)\n",
        "B = np.arange(12).reshape(3,4)\n",
        "C = np.array([1,3,7,2,1,9,5,2,8]).reshape(3,3)\n",
        "I = np.eye(3)\n",
        "UM = np.ones((3,4))\n",
        "ZERO = np.zeros((4,4))\n",
        "D = np.array([9,8,5])\n",
        "UM\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aTpFInLsR3No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 lançamentos de 20 dados\n",
        "dados = np.random.multinomial(20, [1/6.]*6, size=3)\n",
        "alturas = np.random.normal(180, 15, size = (3,6))\n",
        "np.set_printoptions(precision=2)\n",
        "print(alturas, alturas.T, alturas.ravel(), \"\", sep = \"\\n\\n\")\n"
      ],
      "metadata": {
        "id": "YLxeo3skzTFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cA = A.copy()\n",
        "cA[0:2, 1:3] = 3\n",
        "print(A, cA, sep = \"\\n\\n\")"
      ],
      "metadata": {
        "id": "dMwvq85LzQSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.hstack((A,C)), np.vstack((A,C)), sep = \"\\n\\n\")\n",
        "np.concatenate((A**2, B, dados), axis = 1)"
      ],
      "metadata": {
        "id": "EZzkO_QRzqTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = np.arange(12, 0, -1).reshape((3,4))\n",
        "print(Z)\n",
        "np.apply_along_axis(lambda x: np.sort(x), 0, Z)\n"
      ],
      "metadata": {
        "id": "ZNyeXTmbq1Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.fromfunction(lambda x, y: x + 10 * y, (3,2))"
      ],
      "metadata": {
        "id": "ROLwu0CUuVFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(C, D, sep = \"\\n\\n\")\n",
        "np.linalg.solve(C,D)"
      ],
      "metadata": {
        "id": "I0ws9HJPhiZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(1,11)\n",
        "np.outer(x, x)"
      ],
      "metadata": {
        "id": "dioH0_AoLhcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.tile(np.array([1,2,3]), (4,1))"
      ],
      "metadata": {
        "id": "MXFMi-cRhnsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A + [1,0,1]\n"
      ],
      "metadata": {
        "id": "BYi6-CqDhnHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([1,2,4]) @ np.array([2,1,3])"
      ],
      "metadata": {
        "id": "fCd8K6wAhz1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(A, C, sep = \"\\n\\n\")\n",
        "A * C"
      ],
      "metadata": {
        "id": "AvRfmQhK2_4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A @ C"
      ],
      "metadata": {
        "id": "WRkMJXmlnWNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A[(A>2) & (A < 7)]"
      ],
      "metadata": {
        "id": "n-I5qTdUk79H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B[0:2,1:3]\n"
      ],
      "metadata": {
        "id": "JuNld1pA1F12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(*np.nonzero((A>2) & (A < 7))))\n"
      ],
      "metadata": {
        "id": "fNCbRxUF1Iah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A[np.nonzero((A>2) & (A < 7))]\n"
      ],
      "metadata": {
        "id": "YwuTG1wh1LiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B[[0,2,1],[2,1,3]]\n"
      ],
      "metadata": {
        "id": "QGyjEgJ01M-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A[(A>2) & (A < 7)] += 10\n",
        "\n",
        "print(f\"\"\"Matriz:\n",
        "{A}\n",
        "Soma das colunas: {np.sum(A, axis = 0)}\n",
        "Soma das linhas: {np.sum(A, axis = 1)}\n",
        "Soma cumulativa por colunas:\n",
        "{np.cumsum(A, axis = 0)}\n",
        "Soma cumulativa por linhas:\n",
        "{np.cumsum(A, axis = 1)}\n",
        "Soma: {np.sum(A)}\"\"\")\n",
        "\n",
        "np.cumsum(A)"
      ],
      "metadata": {
        "id": "I31sQ_iD1Oni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "N = 8\n",
        "y = np.zeros(N)\n",
        "x1 = np.linspace(0, 10, N, endpoint=True)\n",
        "x2 = np.linspace(0, 10, N, endpoint=False)\n",
        "plt.plot(x1, y, 'o')\n",
        "plt.plot(x2, y + 0.5, 'o')\n",
        "plt.ylim([-0.5, 1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RnVLuSZYW07-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import  matplotlib.pyplot as plt\n",
        "x = np.linspace(-np.pi, np.pi, 100)\n",
        "plt.plot(x, np.sin(x), '--', x, np.cos(x), '-.')"
      ],
      "metadata": {
        "id": "vc70s32iCbfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo de least squares polynomial fit"
      ],
      "metadata": {
        "id": "oQFuR9LmE1Mv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0.0, 1.0, 2.0, 3.0,  4.0,  5.0])\n",
        "y = np.cos(x)\n",
        "\n",
        "#array([0.0, 0.8, 0.9, 0.1, -0.8, -1.0])\n",
        "z = np.polyfit(x, y, 3)\n",
        "p = np.poly1d(z)\n",
        "p5 = np.poly1d(np.polyfit(x, y, 5))\n",
        "xp = np.linspace(-2, 6, 100)\n",
        "plt.plot(x, y, '.', xp, p(xp), '-', xp, p5(xp), '--')\n",
        "plt.ylim(-2,2)"
      ],
      "metadata": {
        "id": "1EfoCQcmDg5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e86fbdec-f61c-46d6-a12d-bb7153a6728b"
      },
      "source": [
        "# Pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "nome = \"Joana Carlos João Filipa Susana\".split()\n",
        "altura = [156, 178, 183, 172, 178]\n",
        "peso = [52,70,74,68,72]\n",
        "\n",
        "pd.DataFrame(dict(nome = nome, altura = altura, peso = peso))"
      ],
      "metadata": {
        "id": "VNe9LfoQmYyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b1866bc-2bbb-4a32-8795-857ba0c94e7f"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
        "dataframe = pd.read_csv(url)\n",
        "dataframe.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "396c0c53-e855-45da-a285-5922a21a72ec"
      },
      "outputs": [],
      "source": [
        "dataframe.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86545493-6129-45b9-9f3d-1faad7f0796a"
      },
      "outputs": [],
      "source": [
        "dataframe = dataframe.drop('Name', axis=1)\n",
        "dataframe[(dataframe['Sex'] == 'female') & (dataframe['Age'] >= 60)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65016b72-1a4a-4df0-9243-7305c3c6a2db"
      },
      "outputs": [],
      "source": [
        "dataframe['Sex'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f74ac97e-32df-4463-b25c-2831485c15a5"
      },
      "outputs": [],
      "source": [
        "dataframe['Pclass'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5efbc309-fcfd-407f-814c-05c5d511757f"
      },
      "outputs": [],
      "source": [
        "dataframe['Pclass'].nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e8c8bd1-f7ad-4c56-9cf1-3e7be9fcda97"
      },
      "source": [
        "# Examples involving grouping\n",
        "This example will:\n",
        "1. drop duplicates by sex\n",
        "1. count line in each group (survived or not)\n",
        "1. Show average age grouped by sex and survived"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a58d87e7-2390-4960-8d1a-6721978b4dc1"
      },
      "outputs": [],
      "source": [
        "dataframe.drop_duplicates(subset=['Sex'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88cd2a13-1f1b-45bb-b1c8-954ac21f64ea"
      },
      "outputs": [],
      "source": [
        "dataframe.groupby('Survived').count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b5c27dc-10cb-48b7-95fd-2f19c219b100"
      },
      "outputs": [],
      "source": [
        "dataframe.groupby('Survived')[\"PassengerId\"].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e8b274e-1a9d-4ce4-9109-0fc87ca035bf"
      },
      "outputs": [],
      "source": [
        " dataframe.groupby(['Sex','Survived'])['Age'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a39edb83-84d8-4aae-9016-8fec3c03abc3"
      },
      "source": [
        "# Handling missing values\n",
        "You may:\n",
        "- drop all lines containing missing values\n",
        "- show lines where the age is not missing\n",
        "- show lines where age is null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90a4ffb8-3f62-4030-a6cb-125d581ede75"
      },
      "outputs": [],
      "source": [
        "dataframe.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b4525b5-6b74-42c3-bd7a-3e4a17cca7bd"
      },
      "outputs": [],
      "source": [
        "dataframe.dropna().head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c3e7417-5283-4f26-9929-b808839aa8cd"
      },
      "outputs": [],
      "source": [
        "dataframe[dataframe.notnull()[\"Age\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1bd94d5-a4ff-43db-9afa-c10fce757275"
      },
      "outputs": [],
      "source": [
        "dataframe[dataframe['Age'].isnull()].head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af624e47-f059-4a84-8297-696cac0951de"
      },
      "source": [
        "# Imputing missing values\n",
        "- Imputing means substituting missing values\n",
        "- In the first example, since some columns are categorical and other numerical, we are using the *most frequent* strategy\n",
        "- In the other example, we are using the median to fill the values for the age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d059cff-f1cf-4d3b-a76d-d6e763bfda0e"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(strategy=\"most_frequent\")\n",
        "df = pd.DataFrame(imp.fit_transform(dataframe))\n",
        "df.columns = dataframe.columns\n",
        "df.index = dataframe.index\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed8fcef2-262f-4435-9c92-c7fd55edff6d"
      },
      "outputs": [],
      "source": [
        "imp = SimpleImputer(strategy='mean')\n",
        "df = dataframe.copy()\n",
        "df['Age'] = imp.fit_transform(dataframe[[\"Age\"]])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e07eacb-e8e8-463e-aa94-501128218ff9"
      },
      "source": [
        "# One hot encoding\n",
        "OHE means substituting a categorical attribute by several binary attributes, one for each value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f097fb4-7da7-4d7e-ba2a-cb513b6a39fc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "dataframe = pd.DataFrame()\n",
        "dataframe[\"Name\"] = \"Rui Joana Francisca Pedro\".split()\n",
        "dataframe[\"Age\"] = [30,20,22,24]\n",
        "dataframe[\"City\"] = \"Braga Porto Coimbra Braga\".split()\n",
        "\n",
        "city_enc = LabelBinarizer()\n",
        "enc = city_enc.fit_transform(dataframe[\"City\"])\n",
        "enc_df = pd.DataFrame(enc, columns = city_enc.classes_)\n",
        "new_df = pd.concat([dataframe, enc_df], axis = 1)#.drop(\"City\", axis = 1)\n",
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f865f0e-0df5-4cf6-b13c-223eb6c57add"
      },
      "source": [
        "# Encoding ordinal features\n",
        "In the case of ordinal features, the strategy is different"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d176785e-fd66-48b3-b3e8-145aaedbfc7a"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame([\n",
        "        dict(name=\"Rui\", age = \"21\", score=\"high\"),\n",
        "        dict(name=\"Clara\", score=\"medium\", age=20),\n",
        "        dict(name=\"Pedro\",age=19,score=\"low\"),\n",
        "        dict(name=\"Joana\",age=19,score=\"high\")])\n",
        "df.score = df.score.replace(dict(low=0, medium=1, high=4))\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fab27ce2-081c-47ab-9311-27c663f71222"
      },
      "source": [
        "# Scaling\n",
        "Example of scaling the values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aca2003-ca71-40d5-952e-2cd1f5d27db4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "new_df[\"Age\"] = scaler.fit_transform(new_df[[\"Age\"]])\n",
        "new_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d02ca551-9ebd-4388-b230-4bfd6e712820"
      },
      "source": [
        "# Standardizing\n",
        "We are substituting **Idade** by the standardized value. In this case, the mean becomes 0 and the standard deviation will be 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "408936c9-fd2d-4a5f-9a4e-2929301c0882"
      },
      "outputs": [],
      "source": [
        "df= pd.DataFrame(np.array([[\"Rui\", 45, \"Braga\"],\n",
        "        [\"Joana\", 29, \"Braga\"],\n",
        "        [\"Carla\", 29, \"Porto\"],\n",
        "        [\"Marcos\", 27, \"Lisboa\"]]), columns = \"Nome Idade Cidade\".split())\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "df[\"Idade\"] = sc.fit_transform(df[[\"Idade\"]])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dda27ee-9303-47f4-be85-280a98786fff"
      },
      "source": [
        "# Applying functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cd19113-cecc-4170-94ce-29bf90090b86"
      },
      "outputs": [],
      "source": [
        "df= pd.DataFrame(np.array([[\"Rui\", 45, \"Braga\"],\n",
        "        [\"Joana\", 29, \"Braga\"],\n",
        "        [\"Carla\", 29, \"Porto\"],\n",
        "        [\"Marcos\", 27, \"Lisboa\"]]), columns = \"Nome Idade Cidade\".split())\n",
        "df[\"Nome\"] = df[\"Nome\"].apply(lambda x: x.upper())\n",
        "df[\"Idade\"] = df[\"Idade\"].astype(int).apply(lambda x : x + 10)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddeb1d71-d571-4103-9e79-063f88fba101"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"Cidade\").apply(lambda x: x.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9516cf79-27e8-4c94-8b47-002c5074b1c4"
      },
      "outputs": [],
      "source": [
        "df.groupby(\"Cidade\")[\"Idade\"].apply(lambda x: x.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8d43d66-0572-4bc7-8098-781172521a23"
      },
      "source": [
        "# Detecting outliers by IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df7dc15f-f60f-481f-8481-46de67f83bd3"
      },
      "outputs": [],
      "source": [
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
        "wine = pd.read_csv(url, sep = \";\")\n",
        "def outliers(x):\n",
        "        q1, q3 = np.percentile(x, [25, 75])\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - (iqr * 1.5)\n",
        "        upper_bound = q3 + (iqr * 1.5)\n",
        "        return (x < lower_bound) | (x > upper_bound)\n",
        "wine[outliers(wine.iloc[:,0])].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33548248-c204-449e-9efa-024e90bde841"
      },
      "source": [
        "# Discretizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54984c23-9439-440d-a6a5-68f169030d5e"
      },
      "outputs": [],
      "source": [
        "nwine = wine.copy()\n",
        "nwine[\"alcoolStrong\"] = np.digitize(wine[\"alcohol\"], [11])\n",
        "nwine[\"alcoholD\"] = np.digitize(wine[\"alcohol\"], np.percentile(wine[\"alcohol\"], [25, 50, 75]))\n",
        "nwine[[\"alcohol\", \"alcoholD\", \"alcoolStrong\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18b46dac-22fb-4120-a561-6e9d88a63960"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6482a91-197b-4e25-91bb-1696626c38ff"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "cmap = sns.cubehelix_palette(rot=-.2, as_cmap=True)\n",
        "\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "sns.relplot(x=\"sepal_length\", y = \"sepal_width\", hue = \"petal_width\", size = \"petal_length\", style = \"species\", palette=cmap, sizes=(10, 200), data  = iris)\n",
        "g = sns.PairGrid(iris, hue = \"species\")\n",
        "g.map_upper(sns.scatterplot)\n",
        "g.map_lower(sns.kdeplot)\n",
        "g.map_diag(sns.kdeplot, lw=3, legend=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4c8b2df-daec-4412-b497-e8ce0b977650"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(iris, hue=\"species\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc5ad10b-250f-4631-b549-a1d702a0ae48"
      },
      "source": [
        "# Example of binarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65647b25-aebe-46b0-a78f-8cf98f994d8f"
      },
      "outputs": [],
      "source": [
        "lenses = \"\"\"young           myope                   no     reduced      none\n",
        "young           myope                   no      normal      soft\n",
        "young           myope                  yes     reduced      none\n",
        "young           myope                  yes      normal      hard\n",
        "young           hypermetrope            no     reduced      none\n",
        "young           hypermetrope            no      normal      soft\n",
        "young           hypermetrope           yes     reduced      none\n",
        "young           hypermetrope           yes      normal      hard\n",
        "pre-PB          myope                   no     reduced      none\n",
        "pre-PB          myope                   no      normal      soft\n",
        "pre-PB          myope                  yes     reduced      none\n",
        "pre-PB          myope                  yes      normal      hard\n",
        "pre-PB          hypermetrope            no     reduced      none\n",
        "pre-PB          hypermetrope            no      normal      soft\n",
        "pre-PB          hypermetrope           yes     reduced      none\n",
        "pre-PB          hypermetrope           yes      normal      none\n",
        "PB              myope                   no     reduced      none\n",
        "PB              myope                   no      normal      none\n",
        "PB              myope                  yes     reduced      none\n",
        "PB              myope                  yes      normal      hard\n",
        "PB              hypermetrope            no     reduced      none\n",
        "PB              hypermetrope            no      normal      soft\n",
        "PB              hypermetrope           yes     reduced      none\n",
        "PBX              hypermetrope           yes      normal      none\"\"\"\n",
        "lenses = pd.DataFrame([line.split() for line in lenses.splitlines()], columns = \"Age Prescription Astigmatism TearProdRate ContactLenses\".split())\n",
        "\n",
        "def add_one_hot(column):\n",
        "    enc = LabelBinarizer()\n",
        "    enc.fit_transform(column)\n",
        "    if len(enc.classes_) > 2:\n",
        "        return pd.DataFrame(enc.fit_transform(column), columns = enc.classes_)\n",
        "    else:\n",
        "        return pd.DataFrame(enc.fit_transform(column), columns = [enc.classes_[0]])\n",
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "for attr in \"Age Prescription Astigmatism TearProdRate\".split():\n",
        "        df = pd.concat([df, add_one_hot(lenses[attr])], axis = 1)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68fed34c-1a96-458d-9f83-b0ab4ef10b2f"
      },
      "source": [
        "# Tutorials\n",
        "\n",
        "- [Numpy](https://numpy.org/doc/stable/user/quickstart.html)\n",
        "- [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)\n",
        "- [Seaborn](https://seaborn.pydata.org/tutorial.html)\n",
        "- [scikit-learn](https://scikit-learn.org/stable/tutorial/index.html)\n"
      ]
    }
  ]
}